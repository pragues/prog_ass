{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> CSC4120 Programming Assignment 3  </h1>\n",
    "\n",
    "## Submission Requirements\n",
    "\n",
    "   The submission <font color = #942F2C>deadline is October 26 (Sun.), 2025, 11:59 pm</font>. Solutions submitted after the deadline will be graded as 0 points. Please submit a **Jupyter Notebook** file using given template and clearly state your group members' student IDs. Otherwise, your points will be deducted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studen IDs\n",
    "\n",
    "Group13\n",
    "\n",
    "122090437 QIU Runheng\n",
    "\n",
    "122090669 YE Shuhuan\n",
    "\n",
    "122090872 JIN Yiyao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Remote Error Correction\n",
    "\n",
    "Prof. Costas was isolated in Xi'an. He was planning to work on the homework during the isolation. Unfortunately, his computer broke and corrupted the latest copy of the homework file. A few lines of the file were affected. Prof. Costas could just ask Mingjie, who was in Shenzhen, to send him the latest copy of the file. But the hotel he stayed has very slow and pricey Internet access.\n",
    "\n",
    "Help Prof. Costas recover the file and prepare homework on time! Design an interactive protocol for detecting and correcting corrupted lines that uses **little communication**.\n",
    "\n",
    "In this question, you have to answer two short-answer questions and implement the following three functions in file_compare.ipynb.\n",
    "(Feel free to add additional methods)\n",
    "\n",
    "* def hash_function(s)\n",
    "* def compute_node_value(table, i, j)\n",
    "* def binary_check_hash(left, right)\n",
    "\n",
    "First, Prof. Costas and Mingjie need a good hash function that can compute a hash value for any contiguous subset of lines of a file.\n",
    "\n",
    "1. Implement a **division hash** in the function *hash_function*.\n",
    "\n",
    "You can use bulit-in function *hash()* (or any other function) to calculate the hash code of a string, but you should make **your** *hash_function* a division hash. \n",
    "\n",
    "2. Implement the function *compute_node_value*.\n",
    "\n",
    "It computes all useful hash values for binary comparison (to be explained later), and store them in corresponding table (HashCorruptedFile[][] and HashOriginalFile[][]). It only calculates HashCorruptedFile[0, n], HashCorruptedFile[0, n/2], HashCorruptedFile[0, n/4], HashCorruptedFile[n/2, n], HashCorruptedFile[n/4, n/2] ... etc\n",
    "\n",
    "Hints:\n",
    "- wordsCorrupted[i] = data of line i in the corrupted file\n",
    "- HashCorruptedFile[i][i] = Hash value of \"line i in the corrupted File\"\n",
    "- HashCorruptedFile[i][j] = Hash value of \"lines i to j in the corrupted File\"\n",
    "\n",
    "For example, if the corrupted file (4 lines) is as follows:\n",
    "\n",
    "aaaa\\n\n",
    "bbbb\\n\n",
    "cccc\\n\n",
    "dddd\n",
    "\n",
    "then,\n",
    "- wordsCorrupted[0] = \"aaaa\"\n",
    "- HashCorruptedFile[0][0] = hash function(\"aaaa\")\n",
    "- HashCorruptedFile[1][1] = hash function(\"bbbb\")\n",
    "- HashCorruptedFile[0][2] = hash function(temp). temp is something related to \"aaaa\",\n",
    "\"bbbb\" and \"cccc\", or related to their hash value. It depends on your own design.\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Prof. Costas and Mingjie have your hash function. They want to find the corrupted lines. Mingjie came up with a naive algorithm to compare both files line by line (and he wrote the codes in *naive_check_hash*). They could send and compare the hash value of each line. But Prof. Costas is unsatisfied with the communication cost $ \\Theta(n) $. Help them design an efficient algorithm! \n",
    "\n",
    "3. Suppose the two copies of the file differ in some number of consecutive lines.\n",
    "Let $ n $ be the total number of lines in the file. How can Prof. Costas and Mingjie use\n",
    "binary search to find the start and end of the corruption by exchanging only $ O(\\log n) $ hash\n",
    "values? Describe your idea below.\n",
    "\n",
    "\\### You answer goes here：\n",
    "\n",
    "Firstly compare the hash of the whole file, if the hashes match then no corruption exists, otherwise there exists some corruptions. \n",
    "\n",
    "Then use the binary search for searching the corruptions: For the start position, compare the hash of [0, mid] between both files and if the hashes match, the corruptions start in the right half and then repeat searching in the right half with range [mid+1, n-1]. If the hashes differ, the corruptions start in the left half and then repeat searching in the left half with range [0, mid]. Repeating the search steps until we can define the starting line.\n",
    "\n",
    "For the end position, compare the hash of [mid, n-1] between both files and if the hashes match, the corruptions end in the left half and then repeat searching in the left half with range [0, mid-1]. If the hashes differ, the corruptions end in the right half and then repeat searching in the right half with range [mid, n-1]. Repeating the search steps until we can define the ending line.\n",
    "\n",
    "With binary search, finding the start position takes $ O(\\log n) $  comparisons, and finding the end position also takes $ O(\\log n) $  comparisons. So it takes $ O(\\log n) $ in total instead of $ \\Theta(n) $.\n",
    "\\###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Let $ W $ ($ W << n $) be the number of corrupted lines (not necessarily consecutive). What can\n",
    "they do to find all corrupted lines by exchanging only $ O(W · \\log n) $ hash values? Describe your idea below.\n",
    "\n",
    "\\### Your answer goes here\n",
    "\n",
    "\\###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Implement *binary_check_hash*.\n",
    "\n",
    "This function simulates the interactive protocol (and is the implementation of your idea in 4). It should call the function *compare* to compare two hash values, print \"[binary_check_hash] found damaged content at line xx\" as *naive_check_hash* does whenever a corrupted line is found, and call the function *send_words* to retrieve the original line from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T13:02:34.033882Z",
     "start_time": "2025-10-11T13:02:34.027863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3b6fab63e057c229e295edf20d4d6a05783919f0bec0797b50be86b0877d9bd49cdee18fe842e6a0711ea48fa1293c556b658c3727f2cd0ebe24291ef1081b07\n",
      "3b6fab63e057c229e295edf20d4d6a05783919f0bec0797b50be86b0877d9bd4\n",
      "{'ripemd160', 'sha3_384', 'md5-sha1', 'shake_128', 'sha1', 'dsaEncryption', 'md4', 'shake_256', 'sha3_224', 'dsaWithSHA', 'GOST 28147-89 MAC', 'blake2s', 'blake2b', 'GOST R 34.11-2012 (256 bit)', 'GOST R 34.11-94', 'sha384', 'GOST R 34-11-2012 (512 bit)', 'md5', 'whirlpool', 'sha512', 'ecdsa-with-SHA1', 'sha224', 'sha256', 'sha3_512', 'sha3_256'}\n",
      "digest:26c60a61d01db5836ca70fefd44a6a016620413c8ef5f259a6c5612d4f79d3b8\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "print(hashlib.shake_256(\"hello\\nworld\".encode('utf-8')).hexdigest(64))\n",
    "print(hashlib.shake_256(\"hello\\nworld\".encode('utf-8')).hexdigest(32))\n",
    "print(hashlib.algorithms_available)\n",
    "\n",
    "s = \"hello\\nworld\"\n",
    "digest = hashlib.sha256(s.encode('utf-8')).hexdigest()\n",
    "print(f\"digest:{digest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hash Values for words in New File\n",
    "# HashCorruptedFile[i,j] = Hash value of lines i to j in Corrupted File\n",
    "HashCorruptedFile = []\n",
    "\n",
    "# Hash Values for words in Old File\n",
    "# HashOriginalFile[i,j] = Hash value of lines i to j in Original File\n",
    "HashOriginalFile = []\n",
    "\n",
    "# Words in the Corrupted and Original File\n",
    "wordsCorrupted = []\n",
    "wordsOriginal = []\n",
    "\n",
    "# n : number of lines in each file\n",
    "n = 1 # default value\n",
    "\n",
    "# variable to measure network transmission cost\n",
    "cost = 0\n",
    "\n",
    "# penalty value for transmitting the whole line\n",
    "penalty = 4\n",
    "\n",
    "\n",
    "# feel free to add additional functions\n",
    "\n",
    "def hash_function(s):\n",
    "    '''\n",
    "    compute and return the hash value of the string s.\n",
    "\n",
    "    You can use built-in hash() (or any other method) to calculate a hash code. But you should finally return a division hash code (something % something). \n",
    "    '''\n",
    "    #######################\n",
    "    #                     #\n",
    "    #      Question 1     #\n",
    "    #     TO IMPLEMENT    #\n",
    "    #                     #\n",
    "    #######################\n",
    "    if s is None:\n",
    "        return 0\n",
    "    import hashlib\n",
    "    digest = hashlib.sha256(s.encode('utf-8')).hexdigest()\n",
    "    print(f\"digest: {digest}\")\n",
    "    big_num = 10**9+7\n",
    "    return digest % big_num\n",
    "\n",
    "\n",
    "def compute_node_values():\n",
    "    ''' \n",
    "    in the first part of compute_hash_tree(), we computed HashOriginalFile[0][0], HashOriginalFile[1][1], HashOriginalFile[2][2].... etc\n",
    "    \n",
    "    Now, here in compute_node_values(), you have to calculate HashOriginalFile[i][j] where i < j\n",
    "    So, HashOriginalFile[2][4] = hash_function(\"line 2-4 of corrupted file\"). It depends on your own design. \n",
    "    \n",
    "    For example, HashOriginalFile[2][4] can be = hash_function(hash_function(line 2) + 2*hash_function(line 3) + 3*hash_function(line 4)).... but it is good? Perhaps not. So, write your own hash function here! \n",
    "    '''\n",
    "    compute_node_value(HashCorruptedFile, 0, n - 1)\n",
    "    compute_node_value(HashOriginalFile, 0, n - 1)\n",
    "\n",
    "def compute_node_value(table, i, j):\n",
    "    '''\n",
    "    it calculates table[i][j], where table could be HashCorruptedFile or HashOriginalFile.\n",
    "\n",
    "    Remember you are doing a binary search here. It's not necessary to try out all combination of i, j. You only need to consider (0, n), (0, n/2), (n/2, n), ... \n",
    "    '''\n",
    "    #######################\n",
    "    #                     #\n",
    "    #      Question 2     #\n",
    "    #     TO IMPLEMENT    #\n",
    "    #                     #\n",
    "    #######################\n",
    "\n",
    "\n",
    "def binary_check_hash(left, right):\n",
    "    ''' \n",
    "    performs binary search over the hash tree.\n",
    "\n",
    "    Search through the whole tree. \n",
    "    The output should be similar to naive_check_hash().\n",
    "    '''\n",
    "    global cost, penalty\n",
    "    #######################\n",
    "    #                     #\n",
    "    #      Question 5     #\n",
    "    #     TO IMPLEMENT    #\n",
    "    #                     #\n",
    "    #######################\n",
    "\n",
    "\n",
    "# read fileCorrupted and fileOriginal, save to wordsCorrupted and wordsOriginal\n",
    "def read_files(fileCorrupted, fileOriginal):\n",
    "    print(\"reading files:\", fileCorrupted, fileOriginal)\n",
    "    with open(fileCorrupted, 'r') as fCorrupted:\n",
    "        for line in fCorrupted:\n",
    "            wordsCorrupted.append(line.rstrip())\n",
    "    with open(fileOriginal, 'r') as fOriginal:\n",
    "        for line in fOriginal:\n",
    "            wordsOriginal.append(line.rstrip())\n",
    "\n",
    "\n",
    "# Compute the hash values of the leaf nodes in the Hash Tree\n",
    "def compute_hash_tree():\n",
    "    for i in range(n):\n",
    "        HashCorruptedFile.append([])\n",
    "        HashOriginalFile.append([])\n",
    "        for _ in range(n):\n",
    "            HashCorruptedFile[i].append(None)\n",
    "            HashOriginalFile[i].append(None)\n",
    "\n",
    "    for i in range(n):\n",
    "        HashCorruptedFile[i][i] = hash_function(wordsCorrupted[i])\n",
    "        HashOriginalFile[i][i] = hash_function(wordsOriginal[i])\n",
    "\n",
    "    compute_node_values()\n",
    "\n",
    "\n",
    "# compares the two hash values. total cost increase by 1\n",
    "def compare(oldhash, newhash):\n",
    "    global cost\n",
    "    cost += 1\n",
    "    return oldhash == newhash\n",
    "\n",
    "\n",
    "# adds the penalty of sending the whole line over network transmission\n",
    "def send_word():\n",
    "    global cost, penalty\n",
    "    cost += penalty\n",
    "\n",
    "# naive hash check method, goes over all the lines and compares them.\n",
    "def naive_check_hash(left, right):\n",
    "    global cost, penalty\n",
    "    for i in range(left, right + 1):\n",
    "        if not compare(HashCorruptedFile[i][i], HashOriginalFile[i][i]):\n",
    "            print(\"[naive_check_hash] found damaged content at line\", i)\n",
    "            send_word()\n",
    "\n",
    "\n",
    "# performs the naive_check_hash algorithm and binary_check_hash algorithm.\n",
    "# compares filename1 and filename2 with n lines each\n",
    "# print out the cost\n",
    "def file_transfer(filename1, filename2, n1):\n",
    "    global cost, n\n",
    "    n = n1\n",
    "\n",
    "    print(\"1. starting computation of hash tree...\")\n",
    "    read_files(filename1, filename2)\n",
    "    compute_hash_tree()\n",
    "    print(\"finished computation of hash tree\\n\")\n",
    "\n",
    "    print(\"2. starting computation of naive_check_hash()...\")\n",
    "    cost = 0\n",
    "    naive_check_hash(0, n - 1)\n",
    "    print(\"cost of navie_check_hash() =\", cost, \"\\n\")\n",
    "\n",
    "    print(\"3. starting computation of binary_check_hash()...\")\n",
    "    cost = 0\n",
    "    binary_check_hash(0, n - 1)\n",
    "    print(\"cost of binary_check_hash() =\", cost, \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_transfer(\"file_corrupted1.txt\", \"file_original1.txt\", 1024)\n",
    "    # file_transfer(\"file_corrupted2.txt\", \"file_original2.txt\", 4096)\n",
    "    # file_transfer(\"file_corrupted3.txt\", \"file_original3.txt\", 16384)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90244c378c7e3257c2f5a89cc828b05c1d67956a5c0682215f78ff63c5f4d2c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
