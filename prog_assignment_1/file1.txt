6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping
6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping
6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping
6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping
6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping
6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping
6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping
6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping6.006 Intro to Algorithmsdocdist11 2 3 4 5 6 7 8 9101 2 3 4 51 2 3 4 5 6 7 8 91011121314151617181920212223Recitation 2September 11, 2013def main():if len(sys.argv) != 3:print "Usage: docdist1.py filename_1 filename_2" else:filename_1 = sys.argv[1]filename_2 = sys.argv[2]document_vector_1 = word_frequencies_for_file(filename_1) document_vector_2 = word_frequencies_for_file(filename_2) distance = vector_angle(document_vector_1,document_vector_2) print "The distance between the documents is: %0.6f (radians)" %distancedef word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef get_words_from_line_list(L): word_list = []for line in L:    words_in_line = get_words_from_string(line)word_list = word_list + words_in_line return word_listdef get_words_from_string(line): word_list = []character_list = []for c in line:if c.isalnum(): character_list.append(c)elif len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word) character_list = []if len(character_list)>0:word = "".join(character_list) word = word.lower() word_list.append(word)return word_list
6.006 Intro to AlgorithmsRecitation 2September 11, 2013def count_frequency(word_list): L = []for new_word in word_list: for entry in L:if new_word == entry[0]: entry[1] = entry[1] + 1 breakelse: L.append([new_word,1])return L1 2 3 4 5 6 7 8 9101 2 3 41 2 3 4 5 6 71 2 3def vector_angle(L1,L2):numerator = inner_product(L1,L2)denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2)) return math.acos(numerator/denominator)def inner_product(L1,L2): sum = 0.0for word1, count1 in L1:for word2, count2 in L2: if word1 == word2:sum += count1 * count2 return sumif __name__ == "__main__": import cProfile cProfile.run("main()")
6.006 Intro to Algorithmsdocdist1 profiler output1 2 3 4 5 67 891011 1213 14 1516 17 18 19202122232425docdist2Recitation 2September 11, 2013The distance between the documents is: 0.574160 (radians) 3354148 function calls in 35.636 CPU seconds   Ordered by: standard name   ncalls  tottime  percall  cumtime  percall filename:lineno(      function)1 23 11 22  0.001    0.001   35.636  0.000    0.000   29.376word_frequencies_for_file)35.636 <string>:1(<module>)14.688 docdist1.py:100( 2.085 docdist1.py:110( 6.255 docdist1.py:125(35.635 docdist1.py:135(main) 0.001 docdist1.py:37( 9.083 docdist1.py:49( 0.000 docdist1.py:61( 5.603 docdist1.py:86( 0.000 {len} 0.000 {math.acos} 0.000 {math.sqrt} 0.000 {method ’append’ of ’ 0.000 {method ’disable’ of ’ 0.000 {method ’isalnum’ of ’ 0.000 {method ’join’ of ’str 0.000 {method ’lower’ of ’ 0.001 {method ’readlines’ of 0.000 {open}  6.255    2.085inner_product)  0.000    0.000vector_angle)0.004 0.004  0.000    0.000read_file) 16.995    8.498get_words_from_line_list)6.2556.25535.635 0.00318.1672 325087      1      11241849 11.205    5.602   11.206count_frequency)0.793    0.000    1.17222663   get_words_from_string)0.034    0.0000.000    0.0000.000    0.0000.145    0.0000.0340.0000.0000.145list’ objects}   1    0.000    0.000                    0.000_lsprof.Profiler’ objects}1300248    0.112    0.000   str’ objects} 232140    0.054    0.000    ’ objects} 232140    0.035    0.000    str’ objects}      2    0.003    0.001          ’file’ objects}      2    0.000    0.0000.1120.0540.0350.0030.0001  def get_words_from_line_list(L):2 3 4word_list = [] for line in L:  words_in_line = get_words_from_string(line)
6.006 Intro to Algorithms Recitation 2 September 11, 2013 5  word_list.extend(words_in_line)61 2 3 4 5 61 2 3 4 5 6 7 8 91 2 3 4 5 6 7 8 9101112131415161718docdist41  def count_frequency(word_list): 2  D={}return word_listdocdist3def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) insertion_sort(freq_mapping)return freq_mappingdef insertion_sort(A): for j in range(len(A)):key = A[j]i = j-1while i>-1 and A[i]>key:A[i+1] = A[i]      i = i-1    A[i+1] = keyreturn Adef inner_product(L1,L2): sum = 0.0i=0j=0while i<len(L1) and j<len(L2):# L1[i:] and L2[j:] yet to be processed if L1[i][0] == L2[j][0]:      # both vectors have this word      sum += L1[i][1] * L2[j][1]      i += 1      j += 1elif L1[i][0] < L2[j][0]:# word L1[i][0] is in L1 but not L2 i += 1else:# word L2[j][0] is in L2 but not L1 j += 1return sum
6.006 Intro to Algorithms Recitation 2 September 11, 20133456  else:for new_word in word_list: if new_word in D:         D[new_word] = D[new_word]+1         D[new_word] = 1return D.items()docdist512 3 4 5 6 77 8translation_table = string.maketrans(string.punctuation+string.   uppercase,    " "*len(string.punctuation)+string.lowercase)def get_words_from_string(line):line = line.translate(translation_table) word_list = line.split()return word_list
6.006 Intro to Algorithmsdocdist61 2 3 4 5 61 2 3 4 5 6 7 8 910111213141516171819202122232425docdist71 2 3 4 5 6 7 8Recitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) freq_mapping = merge_sort(freq_mapping)return freq_mappingdef merge_sort(A): n = len(A)if n==1:return Amid = n//2L = merge_sort(A[:mid]) R = merge_sort(A[mid:]) return merge(L,R)def merge(L,R): i=0j=0answer = []while i<len(L) and j<len(R):if L[i]<R[j]: answer.append(L[i]) i += 1else: answer.append(R[j]) j += 1if i<len(L): answer.extend(L[i:])if j<len(R): answer.extend(R[j:])return answerdef count_frequency(word_list): D = {}for new_word in word_list: if new_word in D:D[new_word] = D[new_word]+1 else:D[new_word] = 1 return D
1 2 3 4 51 2 3 4 5 66.006 Intro to AlgorithmsRecitation 2September 11, 2013def word_frequencies_for_file(filename): line_list = read_file(filename)word_list = get_words_from_line_list(line_list) freq_mapping = count_frequency(word_list) return freq_mappingdef inner_product(D1,D2): sum = 0.0for key in D1:if key in D2:sum += D1[key] * D2[key]return sumdocdist81 2 3 4 5 6 7 8 910def get_words_from_string(string):string = string.translate(translation_table) word_list = string.split()return word_listdef word_frequencies_for_file(filename): text = read_file(filename)word_list = get_words_from_string(text) freq_mapping = count_frequency(word_list) return freq_mapping
